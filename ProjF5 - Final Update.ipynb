{"cells":[{"cell_type":"markdown","metadata":{"id":"QxpO46Ul8qp0","nbgrader":{"grade":false,"locked":true,"solution":false}},"source":["## ProjF5 - Final Model\n","\n","Use this document as a template to provide the evaluation of your final model. You are welcome to go in as much depth as needed.\n","\n","Make sure you keep the sections specified in this template, but you are welcome to add more cells with your code or explanation as needed."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ibqBgqcr8qp3","nbgrader":{"grade":false,"locked":true,"solution":false}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"DVrK750r8qp4","nbgrader":{"grade":false,"locked":true,"solution":false}},"source":["### 1. Load and Prepare Data\n","\n","This should illustrate your code for loading the dataset and the split into training, validation and testing. You can add steps like pre-processing if needed."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WB3iJ5Rl8qp4","nbgrader":{"grade":false,"locked":true,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  eyesight(right)  \\\n","0   35         170          85       97.0             0.9              0.9   \n","1   20         175         110      110.0             0.7              0.9   \n","2   45         155          65       86.0             0.9              0.9   \n","3   45         165          80       94.0             0.8              0.7   \n","4   20         165          60       81.0             1.5              0.1   \n","\n","   hearing(left)  hearing(right)  systolic  relaxation  ...  HDL  LDL  \\\n","0              1               1       118          78  ...   70  142   \n","1              1               1       119          79  ...   71  114   \n","2              1               1       110          80  ...   57  112   \n","3              1               1       158          88  ...   46   91   \n","4              1               1       109          64  ...   47   92   \n","\n","   hemoglobin  Urine protein  serum creatinine   AST   ALT  Gtp  \\\n","0        19.8              1               1.0    61   115  125   \n","1        15.9              1               1.1    19    25   30   \n","2        13.7              3               0.6  1090  1400  276   \n","3        16.9              1               0.9    32    36   36   \n","4        14.9              1               1.2    26    28   15   \n","\n","   dental caries  smoking  \n","0              1        1  \n","1              1        0  \n","2              0        0  \n","3              0        0  \n","4              0        0  \n","\n","[5 rows x 23 columns]\n","age                    0\n","height(cm)             0\n","weight(kg)             0\n","waist(cm)              0\n","eyesight(left)         0\n","eyesight(right)        0\n","hearing(left)          0\n","hearing(right)         0\n","systolic               0\n","relaxation             0\n","fasting blood sugar    0\n","Cholesterol            0\n","triglyceride           0\n","HDL                    0\n","LDL                    0\n","hemoglobin             0\n","Urine protein          0\n","serum creatinine       0\n","AST                    0\n","ALT                    0\n","Gtp                    0\n","dental caries          0\n","smoking                0\n","dtype: int64\n"]}],"source":["import pandas as pd\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","\n","# Load the dataset\n","file_path = 'datasets/train_dataset.csv'  # Update this to the path of your dataset file\n","data = pd.read_csv(file_path)\n","\n","# Display the first few rows of the dataset\n","print(data.head())\n","\n","# Check for missing values\n","print(data.isnull().sum())\n","\n","# Describe the dataset to understand its distribution\n","# print(data.describe())\n","\n","#convert all columns to lowercase\n","data.columns = data.columns.str.lower()\n","\n","#strip all symbols and replace with space, strip all tailing whitespaces and remaining white spaces replaced with underscores \n","data.columns = data.columns.str.replace(r'[^a-zA-Z0-9]', ' ', regex=True).str.strip()\n","data.columns = data.columns.str.replace(' ', '_', regex=True)\n","\n","# If you need to fill missing values, here's a simple way to do it (example)\n","# data.fillna(data.mean(), inplace=True)  # This fills missing values with the mean of each column"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>height_cm</th>\n","      <th>weight_kg</th>\n","      <th>waist_cm</th>\n","      <th>eyesight_left</th>\n","      <th>eyesight_right</th>\n","      <th>hearing_left</th>\n","      <th>hearing_right</th>\n","      <th>systolic</th>\n","      <th>relaxation</th>\n","      <th>...</th>\n","      <th>hdl</th>\n","      <th>ldl</th>\n","      <th>hemoglobin</th>\n","      <th>urine_protein</th>\n","      <th>serum_creatinine</th>\n","      <th>ast</th>\n","      <th>alt</th>\n","      <th>gtp</th>\n","      <th>dental_caries</th>\n","      <th>smoking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>35</td>\n","      <td>170</td>\n","      <td>85</td>\n","      <td>97.0</td>\n","      <td>0.9</td>\n","      <td>0.9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>118</td>\n","      <td>78</td>\n","      <td>...</td>\n","      <td>70</td>\n","      <td>142</td>\n","      <td>19.8</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>61</td>\n","      <td>115</td>\n","      <td>125</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20</td>\n","      <td>175</td>\n","      <td>110</td>\n","      <td>110.0</td>\n","      <td>0.7</td>\n","      <td>0.9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>119</td>\n","      <td>79</td>\n","      <td>...</td>\n","      <td>71</td>\n","      <td>114</td>\n","      <td>15.9</td>\n","      <td>1</td>\n","      <td>1.1</td>\n","      <td>19</td>\n","      <td>25</td>\n","      <td>30</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45</td>\n","      <td>155</td>\n","      <td>65</td>\n","      <td>86.0</td>\n","      <td>0.9</td>\n","      <td>0.9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>110</td>\n","      <td>80</td>\n","      <td>...</td>\n","      <td>57</td>\n","      <td>112</td>\n","      <td>13.7</td>\n","      <td>3</td>\n","      <td>0.6</td>\n","      <td>1090</td>\n","      <td>1400</td>\n","      <td>276</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45</td>\n","      <td>165</td>\n","      <td>80</td>\n","      <td>94.0</td>\n","      <td>0.8</td>\n","      <td>0.7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>158</td>\n","      <td>88</td>\n","      <td>...</td>\n","      <td>46</td>\n","      <td>91</td>\n","      <td>16.9</td>\n","      <td>1</td>\n","      <td>0.9</td>\n","      <td>32</td>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20</td>\n","      <td>165</td>\n","      <td>60</td>\n","      <td>81.0</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>109</td>\n","      <td>64</td>\n","      <td>...</td>\n","      <td>47</td>\n","      <td>92</td>\n","      <td>14.9</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>26</td>\n","      <td>28</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>38979</th>\n","      <td>40</td>\n","      <td>165</td>\n","      <td>60</td>\n","      <td>80.0</td>\n","      <td>0.4</td>\n","      <td>0.6</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>107</td>\n","      <td>60</td>\n","      <td>...</td>\n","      <td>61</td>\n","      <td>72</td>\n","      <td>12.3</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>21</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>38980</th>\n","      <td>45</td>\n","      <td>155</td>\n","      <td>55</td>\n","      <td>75.0</td>\n","      <td>1.5</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>126</td>\n","      <td>72</td>\n","      <td>...</td>\n","      <td>76</td>\n","      <td>131</td>\n","      <td>12.5</td>\n","      <td>2</td>\n","      <td>0.6</td>\n","      <td>23</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>38981</th>\n","      <td>40</td>\n","      <td>170</td>\n","      <td>105</td>\n","      <td>124.0</td>\n","      <td>0.6</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>141</td>\n","      <td>85</td>\n","      <td>...</td>\n","      <td>48</td>\n","      <td>138</td>\n","      <td>17.1</td>\n","      <td>1</td>\n","      <td>0.8</td>\n","      <td>24</td>\n","      <td>23</td>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>38982</th>\n","      <td>40</td>\n","      <td>160</td>\n","      <td>55</td>\n","      <td>75.0</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>95</td>\n","      <td>69</td>\n","      <td>...</td>\n","      <td>79</td>\n","      <td>116</td>\n","      <td>12.0</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>24</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>38983</th>\n","      <td>55</td>\n","      <td>175</td>\n","      <td>60</td>\n","      <td>81.1</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>114</td>\n","      <td>66</td>\n","      <td>...</td>\n","      <td>64</td>\n","      <td>137</td>\n","      <td>13.9</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>18</td>\n","      <td>12</td>\n","      <td>16</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>38984 rows × 23 columns</p>\n","</div>"],"text/plain":["       age  height_cm  weight_kg  waist_cm  eyesight_left  eyesight_right  \\\n","0       35        170         85      97.0            0.9             0.9   \n","1       20        175        110     110.0            0.7             0.9   \n","2       45        155         65      86.0            0.9             0.9   \n","3       45        165         80      94.0            0.8             0.7   \n","4       20        165         60      81.0            1.5             0.1   \n","...    ...        ...        ...       ...            ...             ...   \n","38979   40        165         60      80.0            0.4             0.6   \n","38980   45        155         55      75.0            1.5             1.2   \n","38981   40        170        105     124.0            0.6             0.5   \n","38982   40        160         55      75.0            1.5             1.5   \n","38983   55        175         60      81.1            1.0             1.0   \n","\n","       hearing_left  hearing_right  systolic  relaxation  ...  hdl  ldl  \\\n","0                 1              1       118          78  ...   70  142   \n","1                 1              1       119          79  ...   71  114   \n","2                 1              1       110          80  ...   57  112   \n","3                 1              1       158          88  ...   46   91   \n","4                 1              1       109          64  ...   47   92   \n","...             ...            ...       ...         ...  ...  ...  ...   \n","38979             1              1       107          60  ...   61   72   \n","38980             1              1       126          72  ...   76  131   \n","38981             1              1       141          85  ...   48  138   \n","38982             1              1        95          69  ...   79  116   \n","38983             1              1       114          66  ...   64  137   \n","\n","       hemoglobin  urine_protein  serum_creatinine   ast   alt  gtp  \\\n","0            19.8              1               1.0    61   115  125   \n","1            15.9              1               1.1    19    25   30   \n","2            13.7              3               0.6  1090  1400  276   \n","3            16.9              1               0.9    32    36   36   \n","4            14.9              1               1.2    26    28   15   \n","...           ...            ...               ...   ...   ...  ...   \n","38979        12.3              1               0.5    18    18   21   \n","38980        12.5              2               0.6    23    11   12   \n","38981        17.1              1               0.8    24    23   35   \n","38982        12.0              1               0.6    24    20   17   \n","38983        13.9              1               1.0    18    12   16   \n","\n","       dental_caries  smoking  \n","0                  1        1  \n","1                  1        0  \n","2                  0        0  \n","3                  0        0  \n","4                  0        0  \n","...              ...      ...  \n","38979              1        0  \n","38980              0        0  \n","38981              1        1  \n","38982              0        1  \n","38983              0        1  \n","\n","[38984 rows x 23 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["X, y = data.drop(['smoking'],axis=1),data['smoking']\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def preprocess(df):\n","    df = pd.get_dummies(df,columns = [\"hearing_left\", \"hearing_right\",\"urine_protein\",\"dental_caries\"],dtype = 'int8')\n","    return df"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X = preprocess(X)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Normalize the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)  # This will now be a NumPy array\n","\n","# Ensure y is also a numpy array\n","y = y.values"]},{"cell_type":"markdown","metadata":{"id":"-K3ISILq8qp5"},"source":["### 2. Prepare your Final Model\n","\n","Here you can have your code to either train (e.g., if you are building it from scratch) your model. These steps may require you to use other packages or python files. You can just call them here. You don't have to include them in your submission. Remember that we will be looking at the saved outputs in the notebooked and we will not run the entire notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjTT6eN78qp5"},"outputs":[],"source":["from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from scikeras.wrappers import KerasClassifier \n","from tensorflow.keras.regularizers import l2\n","import tensorflow as tf\n","\n","# Define a function to create the Keras model\n","def create_model(neurons=128, l2_rate=0.01):\n","    model = Sequential([\n","        Dense(neurons, activation='relu', input_dim=X.shape[1], kernel_regularizer=l2(l2_rate)),\n","        Dense(neurons, activation='relu', kernel_regularizer=l2(l2_rate)),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Wrap the model using KerasClassifier\n","model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# Define the grid search parameters\n","param_grid = {\n","    'model__neurons': [64, 128],\n","    'model__l2_rate': [0.001, 0.01, 0.02],\n","    'batch_size': [32, 64],\n","    'epochs': [20, 50]\n","}\n","\n","# Setup cross-validation and grid search\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=kfold)\n","\n","# Perform grid search with cross-validation\n","grid_result = grid.fit(X, y)  # No need to pre-scale; it will be handled internally by the grid search\n","\n","# Summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Best: 0.731351 using {'batch_size': 32, 'epochs': 50, 'model__l2_rate': 0.01, 'model__neurons': 64}\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"4hJphdA_CJL8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,auc_1,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,auc_2,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,auc_3,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,auc_4,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,auc_5,loss\n","  current = self.get_monitor_value(logs)\n"]},{"name":"stdout","output_type":"stream","text":["Average accuracy: 0.78, with standard deviation: 0.01\n"]}],"source":["# Function to create the model, now just returning the model instance\n","from tensorflow.keras.models import Sequential\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.metrics import AUC, Accuracy\n","\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","# Define the K-fold cross validator\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Calculate class weights\n","class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n","\n","class_weights = dict(enumerate(class_weights))\n","\n","def create_optimized_model(neurons = 64):\n","    model = Sequential([\n","        Input(shape = (X_scaled.shape[1],)),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","\n","        BatchNormalization(),\n","        Dropout(0.5),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    optimizer = Adam(learning_rate=0.01)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[AUC(), 'accuracy'])\n","    return model\n","\n","# Assuming you have a setup for training and validation splits\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n","    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","]\n","# List to store each fold's accuracy\n","accuracies = []\n","aucs = []\n","# K-fold Cross Validation model evaluation\n","for train, test in kfold.split(X_scaled, y):\n","    model = create_optimized_model()\n","    # Fit data to model\n","    model.fit(X_scaled[train], y[train], epochs=20, batch_size=32, callbacks=callbacks, class_weight=class_weights, verbose=0)\n","    # Evaluate the model\n","    _, accuracy, auc = model.evaluate(X_scaled[test], y[test], verbose=0)\n","    accuracies.append(accuracy)\n","    aucs.append(auc)\n","\n","# Print out the average and the standard deviation of the accuracies\n","average_accuracy = np.mean(accuracies)\n","std_deviation_accuracy = np.std(accuracies)\n","print(f'Average accuracy: {average_accuracy:.2f}, with standard deviation: {std_deviation_accuracy:.2f}')\n","\n","#Average accuracy: 0.69, with standard deviation: 0.01"]},{"cell_type":"markdown","metadata":{},"source":["### SMOTE"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from imblearn.over_sampling import SMOTE"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796us/step - accuracy: 0.7067 - loss: 0.8503\n","Epoch 2/50\n","\u001b[1m 186/1234\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7113 - loss: 0.6816"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7191 - loss: 0.6722\n","Epoch 3/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7225 - loss: 0.6611\n","Epoch 4/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7189 - loss: 0.6600\n","Epoch 5/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.7193 - loss: 0.6523\n","Epoch 6/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7183 - loss: 0.6482\n","Epoch 7/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7216 - loss: 0.6441\n","Epoch 8/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.7189 - loss: 0.6397\n","Epoch 9/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7190 - loss: 0.6340\n","Epoch 10/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.7222 - loss: 0.6299\n","Epoch 11/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7205 - loss: 0.6282\n","Epoch 12/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7239 - loss: 0.6269\n","Epoch 13/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.6242\n","Epoch 14/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.7232 - loss: 0.6207\n","Epoch 15/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7189 - loss: 0.6264\n","Epoch 16/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.7177 - loss: 0.6271\n","Epoch 17/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7235 - loss: 0.6216\n","Epoch 18/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.7205 - loss: 0.6216\n","Epoch 19/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7194 - loss: 0.6197\n","Epoch 20/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7213 - loss: 0.6183\n","Epoch 21/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7161 - loss: 0.6225\n","Epoch 22/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7194 - loss: 0.6194\n","Epoch 23/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.7199 - loss: 0.6143\n","Epoch 24/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7189 - loss: 0.6189\n","Epoch 25/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7187 - loss: 0.6135\n","Epoch 26/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7191 - loss: 0.6166\n","Epoch 27/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7162 - loss: 0.6138\n","Epoch 28/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.7181 - loss: 0.6125\n","Epoch 29/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7216 - loss: 0.6073\n","Epoch 30/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.7247 - loss: 0.6040\n","Epoch 31/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.7191 - loss: 0.6101\n","Epoch 32/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7221 - loss: 0.6034\n","Epoch 33/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.6099\n","Epoch 34/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7255 - loss: 0.5989\n","Epoch 35/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7173 - loss: 0.6114\n","Epoch 36/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.7167 - loss: 0.6103\n","Epoch 37/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7213 - loss: 0.6038\n","Epoch 38/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7181 - loss: 0.6072\n","Epoch 39/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7223 - loss: 0.6059\n","Epoch 40/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7200 - loss: 0.6034\n","Epoch 41/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7176 - loss: 0.6069\n","Epoch 42/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.7210 - loss: 0.6015\n","Epoch 43/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.7183 - loss: 0.6073\n","Epoch 44/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7146 - loss: 0.6080\n","Epoch 45/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7243 - loss: 0.6032\n","Epoch 46/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7189 - loss: 0.6037\n","Epoch 47/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7242 - loss: 0.6017\n","Epoch 48/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7184 - loss: 0.6059\n","Epoch 49/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7197 - loss: 0.6077\n","Epoch 50/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7246 - loss: 0.5970\n","Epoch 1/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 826us/step - accuracy: 0.7128 - loss: 0.8420\n","Epoch 2/50\n","\u001b[1m 185/1234\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.7310 - loss: 0.6540"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7235 - loss: 0.6648\n","Epoch 3/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7253 - loss: 0.6543\n","Epoch 4/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7225 - loss: 0.6529\n","Epoch 5/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7229 - loss: 0.6518\n","Epoch 6/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7217 - loss: 0.6434\n","Epoch 7/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7190 - loss: 0.6427\n","Epoch 8/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7265 - loss: 0.6332\n","Epoch 9/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.7195 - loss: 0.6379\n","Epoch 10/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7230 - loss: 0.6312\n","Epoch 11/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7207 - loss: 0.6317\n","Epoch 12/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7215 - loss: 0.6323\n","Epoch 13/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7153 - loss: 0.6294\n","Epoch 14/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.7215 - loss: 0.6244\n","Epoch 15/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7190 - loss: 0.6244\n","Epoch 16/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7248 - loss: 0.6149\n","Epoch 17/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.7160 - loss: 0.6220\n","Epoch 18/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7201 - loss: 0.6207\n","Epoch 19/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7213 - loss: 0.6193\n","Epoch 20/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7174 - loss: 0.6199\n","Epoch 21/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7236 - loss: 0.6122\n","Epoch 22/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.7217 - loss: 0.6153\n","Epoch 23/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7196 - loss: 0.6189\n","Epoch 24/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.7165 - loss: 0.6187\n","Epoch 25/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7222 - loss: 0.6161\n","Epoch 26/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.7193 - loss: 0.6166\n","Epoch 27/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7224 - loss: 0.6107\n","Epoch 28/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7204 - loss: 0.6161\n","Epoch 29/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7212 - loss: 0.6152\n","Epoch 30/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7204 - loss: 0.6092\n","Epoch 31/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.7193 - loss: 0.6079\n","Epoch 32/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7185 - loss: 0.6128\n","Epoch 33/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7162 - loss: 0.6101\n","Epoch 34/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7170 - loss: 0.6130\n","Epoch 35/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - accuracy: 0.7221 - loss: 0.6057\n","Epoch 36/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7206 - loss: 0.6076\n","Epoch 37/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7184 - loss: 0.6076\n","Epoch 38/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.7252 - loss: 0.6025\n","Epoch 39/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7211 - loss: 0.6104\n","Epoch 40/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7199 - loss: 0.6066\n","Epoch 41/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7197 - loss: 0.6066\n","Epoch 42/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7159 - loss: 0.6104\n","Epoch 43/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7205 - loss: 0.6130\n","Epoch 44/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.7163 - loss: 0.6098\n","Epoch 45/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7207 - loss: 0.6062\n","Epoch 46/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7204 - loss: 0.6060  \n","Epoch 47/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.6002\n","Epoch 48/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.7223 - loss: 0.6039\n","Epoch 49/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7194 - loss: 0.6055\n","Epoch 50/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7228 - loss: 0.6066\n","Epoch 1/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786us/step - accuracy: 0.7153 - loss: 0.8338\n","Epoch 2/50\n","\u001b[1m 193/1234\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7092 - loss: 0.6871"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7175 - loss: 0.6750\n","Epoch 3/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7206 - loss: 0.6661\n","Epoch 4/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.7207 - loss: 0.6543\n","Epoch 5/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7239 - loss: 0.6415\n","Epoch 6/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.7227 - loss: 0.6398\n","Epoch 7/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.7238 - loss: 0.6385\n","Epoch 8/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.7223 - loss: 0.6388\n","Epoch 9/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.7192 - loss: 0.6359\n","Epoch 10/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7198 - loss: 0.6321\n","Epoch 11/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7224 - loss: 0.6245\n","Epoch 12/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7209 - loss: 0.6271\n","Epoch 13/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.7249 - loss: 0.6190\n","Epoch 14/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7219 - loss: 0.6186\n","Epoch 15/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7211 - loss: 0.6181\n","Epoch 16/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7216 - loss: 0.6227\n","Epoch 17/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.7249 - loss: 0.6150\n","Epoch 18/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7180 - loss: 0.6175\n","Epoch 19/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7205 - loss: 0.6118\n","Epoch 20/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7207 - loss: 0.6159\n","Epoch 21/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7250 - loss: 0.6117\n","Epoch 22/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.7180 - loss: 0.6175\n","Epoch 23/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 0.7207 - loss: 0.6108\n","Epoch 24/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7248 - loss: 0.6054\n","Epoch 25/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7199 - loss: 0.6105\n","Epoch 26/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.7232 - loss: 0.6076\n","Epoch 27/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7210 - loss: 0.6072\n","Epoch 28/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7234 - loss: 0.6022\n","Epoch 29/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.7233 - loss: 0.6025\n","Epoch 30/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.7234 - loss: 0.6035\n","Epoch 31/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7210 - loss: 0.5993\n","Epoch 32/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7188 - loss: 0.6063\n","Epoch 33/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7236 - loss: 0.6070\n","Epoch 34/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.7262 - loss: 0.5980\n","Epoch 35/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.7241 - loss: 0.6067\n","Epoch 36/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7201 - loss: 0.6077\n","Epoch 37/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7229 - loss: 0.6055\n","Epoch 38/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7206 - loss: 0.6042\n","Epoch 39/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7178 - loss: 0.6075\n","Epoch 40/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.7233 - loss: 0.6008\n","Epoch 41/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.7120 - loss: 0.6118\n","Epoch 42/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.7201 - loss: 0.6054\n","Epoch 43/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7161 - loss: 0.6092\n","Epoch 44/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7276 - loss: 0.5980\n","Epoch 45/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7256 - loss: 0.6009\n","Epoch 46/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.7196 - loss: 0.6104\n","Epoch 47/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7198 - loss: 0.6050\n","Epoch 48/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.7205 - loss: 0.6076\n","Epoch 49/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.7200 - loss: 0.6010\n","Epoch 50/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.7197 - loss: 0.6078\n","Epoch 1/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 857us/step - accuracy: 0.7058 - loss: 0.8593\n","Epoch 2/50\n","\u001b[1m 186/1234\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.7275 - loss: 0.6660"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.7248 - loss: 0.6665\n","Epoch 3/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7200 - loss: 0.6694\n","Epoch 4/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.6586\n","Epoch 5/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.6504\n","Epoch 6/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.7233 - loss: 0.6470\n","Epoch 7/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7194 - loss: 0.6447\n","Epoch 8/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.7208 - loss: 0.6435\n","Epoch 9/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7234 - loss: 0.6376\n","Epoch 10/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.7201 - loss: 0.6397\n","Epoch 11/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7251 - loss: 0.6384\n","Epoch 12/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.6400\n","Epoch 13/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.6409\n","Epoch 14/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.7253 - loss: 0.6291\n","Epoch 15/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7178 - loss: 0.6368\n","Epoch 16/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.7222 - loss: 0.6303\n","Epoch 17/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7238 - loss: 0.6260\n","Epoch 18/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.7199 - loss: 0.6285\n","Epoch 19/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.7190 - loss: 0.6287\n","Epoch 20/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7180 - loss: 0.6272\n","Epoch 21/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.7183 - loss: 0.6277\n","Epoch 22/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.7297 - loss: 0.6133\n","Epoch 23/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7190 - loss: 0.6242\n","Epoch 24/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7197 - loss: 0.6224\n","Epoch 25/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7189 - loss: 0.6255\n","Epoch 26/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7232 - loss: 0.6170\n","Epoch 27/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.7263 - loss: 0.6078\n","Epoch 28/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7190 - loss: 0.6200\n","Epoch 29/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7197 - loss: 0.6199\n","Epoch 30/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.7199 - loss: 0.6161\n","Epoch 31/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.7234 - loss: 0.6109\n","Epoch 32/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7230 - loss: 0.6122\n","Epoch 33/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.7209 - loss: 0.6167\n","Epoch 34/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.7159 - loss: 0.6198\n","Epoch 35/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.7245 - loss: 0.6102\n","Epoch 36/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7177 - loss: 0.6166\n","Epoch 37/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7228 - loss: 0.6098\n","Epoch 38/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7238 - loss: 0.6104\n","Epoch 39/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.7187 - loss: 0.6180\n","Epoch 40/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7218 - loss: 0.6145\n","Epoch 41/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.7174 - loss: 0.6210\n","Epoch 42/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.7203 - loss: 0.6114\n","Epoch 43/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.7201 - loss: 0.6156\n","Epoch 44/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7163 - loss: 0.6152\n","Epoch 45/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.7251 - loss: 0.6042\n","Epoch 46/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7183 - loss: 0.6115\n","Epoch 47/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7193 - loss: 0.6102\n","Epoch 48/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.7219 - loss: 0.6068\n","Epoch 49/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7187 - loss: 0.6096\n","Epoch 50/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.7199 - loss: 0.6033\n","Epoch 1/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 808us/step - accuracy: 0.7087 - loss: 0.8567\n","Epoch 2/50\n","\u001b[1m 192/1234\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.7113 - loss: 0.6896"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7169 - loss: 0.6791\n","Epoch 3/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.7227 - loss: 0.6661\n","Epoch 4/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7204 - loss: 0.6537\n","Epoch 5/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.7226 - loss: 0.6519\n","Epoch 6/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.6430\n","Epoch 7/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.6318\n","Epoch 8/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.7171 - loss: 0.6420\n","Epoch 9/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.7149 - loss: 0.6370\n","Epoch 10/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7211 - loss: 0.6309\n","Epoch 11/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.7193 - loss: 0.6315\n","Epoch 12/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.7227 - loss: 0.6263\n","Epoch 13/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7250 - loss: 0.6272\n","Epoch 14/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7192 - loss: 0.6240\n","Epoch 15/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7184 - loss: 0.6276\n","Epoch 16/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.7181 - loss: 0.6242\n","Epoch 17/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.6206\n","Epoch 18/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.7161 - loss: 0.6275\n","Epoch 19/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7185 - loss: 0.6221\n","Epoch 20/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7187 - loss: 0.6218\n","Epoch 21/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.7205 - loss: 0.6172\n","Epoch 22/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7219 - loss: 0.6169\n","Epoch 23/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.7153 - loss: 0.6208\n","Epoch 24/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7246 - loss: 0.6137\n","Epoch 25/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7198 - loss: 0.6162\n","Epoch 26/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7236 - loss: 0.6084\n","Epoch 27/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7236 - loss: 0.6051\n","Epoch 28/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.7199 - loss: 0.6102\n","Epoch 29/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7220 - loss: 0.6075\n","Epoch 30/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7237 - loss: 0.6064\n","Epoch 31/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7213 - loss: 0.6068\n","Epoch 32/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7249 - loss: 0.6022\n","Epoch 33/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7191 - loss: 0.6103\n","Epoch 34/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.7210 - loss: 0.6023\n","Epoch 35/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7214 - loss: 0.6079\n","Epoch 36/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.7225 - loss: 0.6077\n","Epoch 37/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7203 - loss: 0.6053\n","Epoch 38/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7257 - loss: 0.6006\n","Epoch 39/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.7199 - loss: 0.6073\n","Epoch 40/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.6047\n","Epoch 41/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.6066\n","Epoch 42/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7238 - loss: 0.6028\n","Epoch 43/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7242 - loss: 0.6053\n","Epoch 44/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7241 - loss: 0.6026\n","Epoch 45/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7245 - loss: 0.6015\n","Epoch 46/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7194 - loss: 0.6069\n","Epoch 47/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.7264 - loss: 0.5987\n","Epoch 48/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7223 - loss: 0.6030\n","Epoch 49/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7234 - loss: 0.6041\n","Epoch 50/50\n","\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7227 - loss: 0.6048\n","Average accuracy: 0.69, with standard deviation: 0.01\n"]}],"source":["# Function to create the model, now just returning the model instance\n","from tensorflow.keras.models import Sequential\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","# Define the K-fold cross validator\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Calculate class weights\n","class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n","\n","class_weights = dict(enumerate(class_weights))\n","\n","def create_optimized_model(neurons = 64):\n","    model = Sequential([\n","        Input(shape = (X_scaled.shape[1],)),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(64, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    optimizer = Adam(learning_rate=0.01)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Assuming you have a setup for training and validation splits\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n","    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","]\n","# List to store each fold's accuracy\n","accuracies = []\n","\n","# K-fold Cross Validation model evaluation\n","for train, test in kfold.split(X_scaled, y):\n","\n","    smote = SMOTE(random_state=42)\n","    X_train_scaled, y_train_scaled = smote.fit_resample(X_scaled[train], y[train])\n","    \n","    model = create_optimized_model()\n","    # Fit data to model\n","    model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n","    # Evaluate the model\n","    _, accuracy = model.evaluate(X_scaled[test], y[test], verbose=0)\n","    accuracies.append(accuracy)\n","\n","# Print out the average and the standard deviation of the accuracies\n","average_accuracy = np.mean(accuracies)\n","std_deviation_accuracy = np.std(accuracies)\n","print(f'Average accuracy: {average_accuracy:.2f}, with standard deviation: {std_deviation_accuracy:.2f}')\n","\n","#Average accuracy: 0.70, with standard deviation: 0.01"]},{"cell_type":"markdown","metadata":{},"source":["3. Model Performance\n","Make sure to include the following:\n","\n","Performance on the training set\n","Performance on the test set\n","Provide some screenshots of your output (e.g., pictures, text output, or a histogram of predicted values in the case of tabular data). Any visualization of the predictions are welcome."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 [3.10]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
