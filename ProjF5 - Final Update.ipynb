{"cells":[{"cell_type":"markdown","metadata":{"id":"QxpO46Ul8qp0","nbgrader":{"grade":false,"locked":true,"solution":false}},"source":["## ProjF5 - Final Model\n","\n","Use this document as a template to provide the evaluation of your final model. You are welcome to go in as much depth as needed.\n","\n","Make sure you keep the sections specified in this template, but you are welcome to add more cells with your code or explanation as needed."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ibqBgqcr8qp3","nbgrader":{"grade":false,"locked":true,"solution":false}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"DVrK750r8qp4","nbgrader":{"grade":false,"locked":true,"solution":false}},"source":["### 1. Load and Prepare Data\n","\n","This should illustrate your code for loading the dataset and the split into training, validation and testing. You can add steps like pre-processing if needed."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WB3iJ5Rl8qp4","nbgrader":{"grade":false,"locked":true,"solution":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  eyesight(right)  \\\n","0   35         170          85       97.0             0.9              0.9   \n","1   20         175         110      110.0             0.7              0.9   \n","2   45         155          65       86.0             0.9              0.9   \n","3   45         165          80       94.0             0.8              0.7   \n","4   20         165          60       81.0             1.5              0.1   \n","\n","   hearing(left)  hearing(right)  systolic  relaxation  ...  HDL  LDL  \\\n","0              1               1       118          78  ...   70  142   \n","1              1               1       119          79  ...   71  114   \n","2              1               1       110          80  ...   57  112   \n","3              1               1       158          88  ...   46   91   \n","4              1               1       109          64  ...   47   92   \n","\n","   hemoglobin  Urine protein  serum creatinine   AST   ALT  Gtp  \\\n","0        19.8              1               1.0    61   115  125   \n","1        15.9              1               1.1    19    25   30   \n","2        13.7              3               0.6  1090  1400  276   \n","3        16.9              1               0.9    32    36   36   \n","4        14.9              1               1.2    26    28   15   \n","\n","   dental caries  smoking  \n","0              1        1  \n","1              1        0  \n","2              0        0  \n","3              0        0  \n","4              0        0  \n","\n","[5 rows x 23 columns]\n","age                    0\n","height(cm)             0\n","weight(kg)             0\n","waist(cm)              0\n","eyesight(left)         0\n","eyesight(right)        0\n","hearing(left)          0\n","hearing(right)         0\n","systolic               0\n","relaxation             0\n","fasting blood sugar    0\n","Cholesterol            0\n","triglyceride           0\n","HDL                    0\n","LDL                    0\n","hemoglobin             0\n","Urine protein          0\n","serum creatinine       0\n","AST                    0\n","ALT                    0\n","Gtp                    0\n","dental caries          0\n","smoking                0\n","dtype: int64\n","                age    height(cm)    weight(kg)     waist(cm)  eyesight(left)  \\\n","count  38984.000000  38984.000000  38984.000000  38984.000000    38984.000000   \n","mean      44.127591    164.689488     65.938718     82.062115        1.014955   \n","std       12.063564      9.187507     12.896581      9.326798        0.498527   \n","min       20.000000    130.000000     30.000000     51.000000        0.100000   \n","25%       40.000000    160.000000     55.000000     76.000000        0.800000   \n","50%       40.000000    165.000000     65.000000     82.000000        1.000000   \n","75%       55.000000    170.000000     75.000000     88.000000        1.200000   \n","max       85.000000    190.000000    135.000000    129.000000        9.900000   \n","\n","       eyesight(right)  hearing(left)  hearing(right)      systolic  \\\n","count     38984.000000   38984.000000    38984.000000  38984.000000   \n","mean          1.008768       1.025369        1.026190    121.475631   \n","std           0.493813       0.157246        0.159703     13.643521   \n","min           0.100000       1.000000        1.000000     71.000000   \n","25%           0.800000       1.000000        1.000000    112.000000   \n","50%           1.000000       1.000000        1.000000    120.000000   \n","75%           1.200000       1.000000        1.000000    130.000000   \n","max           9.900000       2.000000        2.000000    233.000000   \n","\n","         relaxation  ...           HDL           LDL    hemoglobin  \\\n","count  38984.000000  ...  38984.000000  38984.000000  38984.000000   \n","mean      75.994408  ...     57.293146    115.081495     14.624264   \n","std        9.658734  ...     14.617822     42.883163      1.566528   \n","min       40.000000  ...      4.000000      1.000000      4.900000   \n","25%       70.000000  ...     47.000000     91.000000     13.600000   \n","50%       76.000000  ...     55.000000    113.000000     14.800000   \n","75%       82.000000  ...     66.000000    136.000000     15.800000   \n","max      146.000000  ...    359.000000   1860.000000     21.100000   \n","\n","       Urine protein  serum creatinine           AST           ALT  \\\n","count   38984.000000      38984.000000  38984.000000  38984.000000   \n","mean        1.086523          0.886030     26.198235     27.145188   \n","std         0.402107          0.220621     19.175595     31.309945   \n","min         1.000000          0.100000      6.000000      1.000000   \n","25%         1.000000          0.800000     19.000000     15.000000   \n","50%         1.000000          0.900000     23.000000     21.000000   \n","75%         1.000000          1.000000     29.000000     31.000000   \n","max         6.000000         11.600000   1090.000000   2914.000000   \n","\n","                Gtp  dental caries       smoking  \n","count  38984.000000   38984.000000  38984.000000  \n","mean      39.905038       0.214421      0.367279  \n","std       49.693843       0.410426      0.482070  \n","min        2.000000       0.000000      0.000000  \n","25%       17.000000       0.000000      0.000000  \n","50%       26.000000       0.000000      0.000000  \n","75%       44.000000       0.000000      1.000000  \n","max      999.000000       1.000000      1.000000  \n","\n","[8 rows x 23 columns]\n"]}],"source":["import pandas as pd\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","\n","# Load the dataset\n","file_path = 'datasets/train_dataset.csv'  # Update this to the path of your dataset file\n","data = pd.read_csv(file_path)\n","\n","# Display the first few rows of the dataset\n","print(data.head())\n","\n","# Check for missing values\n","print(data.isnull().sum())\n","\n","# Describe the dataset to understand its distribution\n","print(data.describe())\n","\n","#convert all columns to lowercase\n","data.columns = data.columns.str.lower()\n","\n","#strip all symbols and replace with space, strip all tailing whitespaces and remaining white spaces replaced with underscores \n","data.columns = data.columns.str.replace(r'[^a-zA-Z0-9]', ' ', regex=True).str.strip()\n","data.columns = data.columns.str.replace(' ', '_', regex=True)\n","\n","# If you need to fill missing values, here's a simple way to do it (example)\n","# data.fillna(data.mean(), inplace=True)  # This fills missing values with the mean of each column\n","\n","# You might also want to normalize/standardize your data if you are using neural networks\n","xvars = ['age', 'height_cm', 'weight_kg', 'waist_cm', 'eyesight_left',\n","         'eyesight_right', 'hearing_left', 'hearing_right', 'systolic',\n","         'relaxation', 'fasting_blood_sugar', 'cholesterol', 'triglyceride',\n","         'hdl', 'ldl', 'hemoglobin', 'urine_protein', 'serum_creatinine', 'ast',\n","         'alt', 'gtp', 'dental_caries']\n","yvar = 'smoking'\n","\n","# Select features and target\n","X = data[xvars]\n","y = data[yvar]  # Assuming this is binary (0 = non-smoker, 1 = smoker)\n","\n","# Normalize the data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)  # This will now be a NumPy array\n","\n","# Ensure y is also a numpy array\n","y = y.values\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-K3ISILq8qp5"},"source":["### 2. Prepare your Final Model\n","\n","Here you can have your code to either train (e.g., if you are building it from scratch) your model. These steps may require you to use other packages or python files. You can just call them here. You don't have to include them in your submission. Remember that we will be looking at the saved outputs in the notebooked and we will not run the entire notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjTT6eN78qp5"},"outputs":[],"source":["from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from scikeras.wrappers import KerasClassifier \n","from tensorflow.keras.regularizers import l2\n","import tensorflow as tf\n","\n","# Define a function to create the Keras model\n","def create_model(neurons=128, l2_rate=0.01):\n","    model = Sequential([\n","        Dense(neurons, activation='relu', input_dim=X.shape[1], kernel_regularizer=l2(l2_rate)),\n","        Dense(neurons, activation='relu', kernel_regularizer=l2(l2_rate)),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Wrap the model using KerasClassifier\n","model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# Define the grid search parameters\n","param_grid = {\n","    'model__neurons': [64, 128],\n","    'model__l2_rate': [0.001, 0.01, 0.02],\n","    'batch_size': [32, 64],\n","    'epochs': [20, 50]\n","}\n","\n","# Setup cross-validation and grid search\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=kfold)\n","\n","# Perform grid search with cross-validation\n","grid_result = grid.fit(X, y)  # No need to pre-scale; it will be handled internally by the grid search\n","\n","# Summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Best: 0.731351 using {'batch_size': 32, 'epochs': 50, 'model__l2_rate': 0.01, 'model__neurons': 64}\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4hJphdA_CJL8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 905us/step - accuracy: 0.6792 - loss: 0.8710\n","Epoch 2/50\n","\u001b[1m108/975\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6899 - loss: 0.6612"]},{"name":"stderr","output_type":"stream","text":["/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:156: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/Users/opheliasin/smokerstatusNNDL/myenv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6868 - loss: 0.6706\n","Epoch 3/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.6835 - loss: 0.6691\n","Epoch 4/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.6837 - loss: 0.6619\n","Epoch 5/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.6806 - loss: 0.6645\n","Epoch 6/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.6827 - loss: 0.6573\n","Epoch 7/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.6847 - loss: 0.6482\n","Epoch 8/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.6788 - loss: 0.6541\n","Epoch 9/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.6818 - loss: 0.6463\n","Epoch 10/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.6889 - loss: 0.6345\n","Epoch 11/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.6826 - loss: 0.6322\n","Epoch 12/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.6828 - loss: 0.6309\n","Epoch 13/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.6810 - loss: 0.6282\n","Epoch 14/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.6798 - loss: 0.6303\n","Epoch 15/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.6844 - loss: 0.6260\n","Epoch 16/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.6822 - loss: 0.6287\n","Epoch 17/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.6795 - loss: 0.6270\n","Epoch 18/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.6829 - loss: 0.6225\n","Epoch 19/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.6737 - loss: 0.6246\n","Epoch 20/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.6819 - loss: 0.6216\n","Epoch 21/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.6856 - loss: 0.6182\n","Epoch 22/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.6759 - loss: 0.6181\n","Epoch 23/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.6787 - loss: 0.6207\n","Epoch 24/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.6820 - loss: 0.6229\n","Epoch 25/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.6830 - loss: 0.6202\n","Epoch 26/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.6771 - loss: 0.6219\n","Epoch 27/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.6797 - loss: 0.6214\n","Epoch 28/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6729 - loss: 0.6204\n","Epoch 29/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.6765 - loss: 0.6153\n","Epoch 30/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.6816 - loss: 0.6156\n","Epoch 31/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.6821 - loss: 0.6144\n","Epoch 32/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6784 - loss: 0.6188\n","Epoch 33/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.6795 - loss: 0.6101\n","Epoch 34/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.6800 - loss: 0.6139\n","Epoch 35/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.6779 - loss: 0.6140\n","Epoch 36/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.6781 - loss: 0.6155\n","Epoch 37/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6770 - loss: 0.6181\n","Epoch 38/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6769 - loss: 0.6180\n","Epoch 39/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.6773 - loss: 0.6158\n","Epoch 40/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6771 - loss: 0.6204\n","Epoch 41/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.6706 - loss: 0.6162\n","Epoch 42/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.6785 - loss: 0.6114\n","Epoch 43/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6778 - loss: 0.6132\n","Epoch 44/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.6746 - loss: 0.6155\n","Epoch 45/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6789 - loss: 0.6069\n","Epoch 46/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6813 - loss: 0.6147\n","Epoch 47/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.6744 - loss: 0.6127\n","Epoch 48/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.6783 - loss: 0.6148\n","Epoch 49/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.6767 - loss: 0.6107\n","Epoch 50/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.6739 - loss: 0.6161\n","Epoch 1/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 831us/step - accuracy: 0.6743 - loss: 0.8883\n","Epoch 2/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.6880 - loss: 0.6745\n","Epoch 3/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.6904 - loss: 0.6575\n","Epoch 4/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.6841 - loss: 0.6596\n","Epoch 5/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6838 - loss: 0.6572\n","Epoch 6/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.6916 - loss: 0.6447\n","Epoch 7/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.6907 - loss: 0.6441\n","Epoch 8/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6837 - loss: 0.6449\n","Epoch 9/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.6911 - loss: 0.6360\n","Epoch 10/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.6913 - loss: 0.6374\n","Epoch 11/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.6867 - loss: 0.6429\n","Epoch 12/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.6840 - loss: 0.6376\n","Epoch 13/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6822 - loss: 0.6367\n","Epoch 14/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6896 - loss: 0.6355\n","Epoch 15/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6849 - loss: 0.6341\n","Epoch 16/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6832 - loss: 0.6318\n","Epoch 17/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6804 - loss: 0.6273\n","Epoch 18/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.6787 - loss: 0.6321\n","Epoch 19/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 0.6326\n","Epoch 20/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.6851 - loss: 0.6249\n","Epoch 21/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.6837 - loss: 0.6314\n","Epoch 22/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.6843 - loss: 0.6281\n","Epoch 23/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6840 - loss: 0.6196\n","Epoch 24/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6784 - loss: 0.6223\n","Epoch 25/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.6819 - loss: 0.6227\n","Epoch 26/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.6832 - loss: 0.6195\n","Epoch 27/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6821 - loss: 0.6212\n","Epoch 28/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.6751 - loss: 0.6241\n","Epoch 29/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.6837 - loss: 0.6261\n","Epoch 30/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6802 - loss: 0.6206\n","Epoch 31/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - accuracy: 0.6856 - loss: 0.6194\n","Epoch 32/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6816 - loss: 0.6231\n","Epoch 33/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6777 - loss: 0.6204\n","Epoch 34/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.6790 - loss: 0.6217\n","Epoch 35/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.6794 - loss: 0.6197\n","Epoch 36/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.6752 - loss: 0.6236\n","Epoch 37/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6784 - loss: 0.6207\n","Epoch 38/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.6769 - loss: 0.6163\n","Epoch 39/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.6844 - loss: 0.6183\n","Epoch 40/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6777 - loss: 0.6219\n","Epoch 41/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6780 - loss: 0.6239\n","Epoch 42/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.6797 - loss: 0.6216\n","Epoch 43/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6787 - loss: 0.6222\n","Epoch 44/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.6825 - loss: 0.6158\n","Epoch 45/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.6751 - loss: 0.6153\n","Epoch 46/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.6795 - loss: 0.6137\n","Epoch 47/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6766 - loss: 0.6184\n","Epoch 48/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.6877 - loss: 0.6148\n","Epoch 49/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.6767 - loss: 0.6148\n","Epoch 50/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.6867 - loss: 0.6104\n","Epoch 1/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 853us/step - accuracy: 0.6792 - loss: 0.8876\n","Epoch 2/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 0.6869 - loss: 0.6682\n","Epoch 3/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.6851 - loss: 0.6659\n","Epoch 4/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.6870 - loss: 0.6557\n","Epoch 5/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.6844 - loss: 0.6553\n","Epoch 6/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6857 - loss: 0.6535\n","Epoch 7/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.6886 - loss: 0.6477\n","Epoch 8/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.6857 - loss: 0.6447\n","Epoch 9/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6882 - loss: 0.6463\n","Epoch 10/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.6776 - loss: 0.6374\n","Epoch 11/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.6797 - loss: 0.6474\n","Epoch 12/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.6777 - loss: 0.6425\n","Epoch 13/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.6395\n","Epoch 14/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6831 - loss: 0.6284\n","Epoch 15/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6813 - loss: 0.6319\n","Epoch 16/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.6821 - loss: 0.6313\n","Epoch 17/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.6262\n","Epoch 18/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.6817 - loss: 0.6228\n","Epoch 19/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.6823 - loss: 0.6305\n","Epoch 20/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6826 - loss: 0.6220\n","Epoch 21/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.6840 - loss: 0.6283\n","Epoch 22/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.6825 - loss: 0.6198\n","Epoch 23/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6810 - loss: 0.6249\n","Epoch 24/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.6793 - loss: 0.6190\n","Epoch 25/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.6820 - loss: 0.6213\n","Epoch 26/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.6805 - loss: 0.6216\n","Epoch 27/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.6761 - loss: 0.6270\n","Epoch 28/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.6830 - loss: 0.6082\n","Epoch 29/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6835 - loss: 0.6082\n","Epoch 30/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.6867 - loss: 0.6131\n","Epoch 31/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.6781 - loss: 0.6131\n","Epoch 32/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.6147\n","Epoch 33/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.6827 - loss: 0.6198\n","Epoch 34/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.6757 - loss: 0.6194\n","Epoch 35/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6825 - loss: 0.6141\n","Epoch 36/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.6770 - loss: 0.6154\n","Epoch 37/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6800 - loss: 0.6157\n","Epoch 38/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.6723 - loss: 0.6137\n","Epoch 39/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6805 - loss: 0.6142\n","Epoch 40/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.6777 - loss: 0.6114\n","Epoch 41/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.6769 - loss: 0.6143\n","Epoch 42/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.6833 - loss: 0.6105\n","Epoch 43/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.6881 - loss: 0.6080\n","Epoch 44/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6829 - loss: 0.6165\n","Epoch 45/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.6801 - loss: 0.6112\n","Epoch 46/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.6808 - loss: 0.6099\n","Epoch 47/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6817 - loss: 0.6060\n","Epoch 48/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.6774 - loss: 0.6123\n","Epoch 49/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.6834 - loss: 0.6090\n","Epoch 50/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.6762 - loss: 0.6104\n","Epoch 1/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.8782\n","Epoch 2/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.6823\n","Epoch 3/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.6891 - loss: 0.6630\n","Epoch 4/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.6865 - loss: 0.6550\n","Epoch 5/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.6820 - loss: 0.6561\n","Epoch 6/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6861 - loss: 0.6459\n","Epoch 7/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6904 - loss: 0.6409\n","Epoch 8/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.6443\n","Epoch 9/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.6455\n","Epoch 10/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.6819 - loss: 0.6431\n","Epoch 11/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6830 - loss: 0.6354\n","Epoch 12/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6844 - loss: 0.6331\n","Epoch 13/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.6329\n","Epoch 14/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6850 - loss: 0.6276\n","Epoch 15/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6798 - loss: 0.6266\n","Epoch 16/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 0.6256\n","Epoch 17/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.6754 - loss: 0.6270\n","Epoch 18/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.6781 - loss: 0.6269\n","Epoch 19/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 0.6199\n","Epoch 20/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6755 - loss: 0.6264\n","Epoch 21/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.6803 - loss: 0.6172\n","Epoch 22/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.6831 - loss: 0.6191\n","Epoch 23/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.6715 - loss: 0.6264\n","Epoch 24/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.6817 - loss: 0.6175\n","Epoch 25/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.6843 - loss: 0.6208\n","Epoch 26/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.6758 - loss: 0.6243\n","Epoch 27/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.6823 - loss: 0.6160\n","Epoch 28/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.6753 - loss: 0.6228\n","Epoch 29/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.6760 - loss: 0.6197\n","Epoch 30/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.6777 - loss: 0.6225\n","Epoch 31/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.6804 - loss: 0.6200\n","Epoch 32/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6781 - loss: 0.6188\n","Epoch 33/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.6739 - loss: 0.6166\n","Epoch 34/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.6726 - loss: 0.6195\n","Epoch 35/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6794 - loss: 0.6204\n","Epoch 36/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.6720 - loss: 0.6166\n","Epoch 37/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.6749 - loss: 0.6183\n","Epoch 38/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.6773 - loss: 0.6197\n","Epoch 39/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.6813 - loss: 0.6087\n","Epoch 40/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.6739 - loss: 0.6209\n","Epoch 41/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6754 - loss: 0.6163\n","Epoch 42/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.6773 - loss: 0.6157\n","Epoch 43/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.6808 - loss: 0.6083\n","Epoch 44/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.6732 - loss: 0.6179\n","Epoch 45/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.6743 - loss: 0.6167\n","Epoch 46/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.6821 - loss: 0.6110\n","Epoch 47/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6772 - loss: 0.6106\n","Epoch 48/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6775 - loss: 0.6121\n","Epoch 49/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 0.6760 - loss: 0.6090\n","Epoch 50/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.6741 - loss: 0.6077\n","Epoch 1/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 841us/step - accuracy: 0.6729 - loss: 0.8924\n","Epoch 2/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.6793 - loss: 0.6757\n","Epoch 3/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.6854 - loss: 0.6657\n","Epoch 4/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.6866 - loss: 0.6610\n","Epoch 5/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.6872 - loss: 0.6539\n","Epoch 6/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.6865 - loss: 0.6478\n","Epoch 7/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.6870 - loss: 0.6392\n","Epoch 8/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.6847 - loss: 0.6412\n","Epoch 9/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.6854 - loss: 0.6384\n","Epoch 10/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.6800 - loss: 0.6398\n","Epoch 11/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6871 - loss: 0.6351\n","Epoch 12/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6801 - loss: 0.6359\n","Epoch 13/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.6800 - loss: 0.6370\n","Epoch 14/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.6831 - loss: 0.6329\n","Epoch 15/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.6805 - loss: 0.6330\n","Epoch 16/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.6815 - loss: 0.6256\n","Epoch 17/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.6770 - loss: 0.6315\n","Epoch 18/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.6873 - loss: 0.6195\n","Epoch 19/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.6809 - loss: 0.6250\n","Epoch 20/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.6747 - loss: 0.6318\n","Epoch 21/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.6769 - loss: 0.6354\n","Epoch 22/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.6847 - loss: 0.6180\n","Epoch 23/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.6814 - loss: 0.6241\n","Epoch 24/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.6829 - loss: 0.6185\n","Epoch 25/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.6841 - loss: 0.6180\n","Epoch 26/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.6792 - loss: 0.6221\n","Epoch 27/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6818 - loss: 0.6240\n","Epoch 28/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.6802 - loss: 0.6202\n","Epoch 29/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.6783 - loss: 0.6158\n","Epoch 30/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6803 - loss: 0.6171\n","Epoch 31/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6767 - loss: 0.6152\n","Epoch 32/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.6202\n","Epoch 33/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.6778 - loss: 0.6229\n","Epoch 34/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.6808 - loss: 0.6158\n","Epoch 35/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.6743 - loss: 0.6173\n","Epoch 36/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 0.6807 - loss: 0.6114\n","Epoch 37/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.6800 - loss: 0.6149\n","Epoch 38/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.6728 - loss: 0.6217\n","Epoch 39/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.6782 - loss: 0.6183\n","Epoch 40/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.6795 - loss: 0.6125\n","Epoch 41/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.6790 - loss: 0.6069\n","Epoch 42/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.6769 - loss: 0.6134\n","Epoch 43/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6714 - loss: 0.6143\n","Epoch 44/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6790 - loss: 0.6075\n","Epoch 45/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6730 - loss: 0.6107\n","Epoch 46/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6737 - loss: 0.6113\n","Epoch 47/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.6150\n","Epoch 48/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.6798 - loss: 0.6104\n","Epoch 49/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6831 - loss: 0.6021\n","Epoch 50/50\n","\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.6083\n","Average accuracy: 0.69, with standard deviation: 0.01\n"]}],"source":["# Function to create the model, now just returning the model instance\n","from tensorflow.keras.models import Sequential\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","# Define the K-fold cross validator\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Calculate class weights\n","class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n","\n","class_weights = dict(enumerate(class_weights))\n","\n","def create_optimized_model(neurons = 64):\n","    model = Sequential([\n","        Input(shape = (X_scaled.shape[1],)),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(64, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    optimizer = Adam(learning_rate=0.01)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Assuming you have a setup for training and validation splits\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n","    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","]\n","# List to store each fold's accuracy\n","accuracies = []\n","\n","# K-fold Cross Validation model evaluation\n","for train, test in kfold.split(X_scaled, y):\n","    model = create_optimized_model()\n","    # Fit data to model\n","    model.fit(X_scaled[train], y[train], epochs=50, batch_size=32, callbacks=callbacks, class_weight=class_weights, verbose=1)\n","    # Evaluate the model\n","    _, accuracy = model.evaluate(X_scaled[test], y[test], verbose=0)\n","    accuracies.append(accuracy)\n","\n","# Print out the average and the standard deviation of the accuracies\n","average_accuracy = np.mean(accuracies)\n","std_deviation_accuracy = np.std(accuracies)\n","print(f'Average accuracy: {average_accuracy:.2f}, with standard deviation: {std_deviation_accuracy:.2f}')\n","\n","#Average accuracy: 0.69, with standard deviation: 0.01"]},{"cell_type":"markdown","metadata":{},"source":["### SMOTE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from imblearn.over_sampling import SMOTE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to create the model, now just returning the model instance\n","from tensorflow.keras.models import Sequential\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Input\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","# Define the K-fold cross validator\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Calculate class weights\n","class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n","\n","class_weights = dict(enumerate(class_weights))\n","\n","def create_optimized_model(neurons = 64):\n","    model = Sequential([\n","        Input(shape = (X_scaled.shape[1],)),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(neurons, kernel_regularizer=l2(0.01)),\n","        BatchNormalization(),\n","        Activation('relu'),\n","        Dropout(0.5),\n","        Dense(64, kernel_regularizer=l2(0.01)),\n","        Activation('relu'),\n","        Dense(1, activation='sigmoid')\n","    ])\n","    optimizer = Adam(learning_rate=0.01)\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Assuming you have a setup for training and validation splits\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n","    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n","]\n","# List to store each fold's accuracy\n","accuracies = []\n","\n","# K-fold Cross Validation model evaluation\n","for train, test in kfold.split(X_scaled, y):\n","\n","    smote = SMOTE(random_state=42)\n","    X_train_scaled, y_train_scaled = smote.fit_resample(X_scaled[train], y[train])\n","    \n","    model = create_optimized_model()\n","    # Fit data to model\n","    model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, callbacks=callbacks, verbose=1)\n","    # Evaluate the model\n","    _, accuracy = model.evaluate(X_scaled[test], y[test], verbose=0)\n","    accuracies.append(accuracy)\n","\n","# Print out the average and the standard deviation of the accuracies\n","average_accuracy = np.mean(accuracies)\n","std_deviation_accuracy = np.std(accuracies)\n","print(f'Average accuracy: {average_accuracy:.2f}, with standard deviation: {std_deviation_accuracy:.2f}')\n","\n","#Average accuracy: 0.70, with standard deviation: 0.01"]},{"cell_type":"markdown","metadata":{},"source":["3. Model Performance\n","Make sure to include the following:\n","\n","Performance on the training set\n","Performance on the test set\n","Provide some screenshots of your output (e.g., pictures, text output, or a histogram of predicted values in the case of tabular data). Any visualization of the predictions are welcome."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 [3.10]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
